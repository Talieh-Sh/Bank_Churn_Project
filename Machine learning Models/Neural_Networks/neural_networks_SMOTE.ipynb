{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import imblearn\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15674932</td>\n",
       "      <td>Okwudilichukwu</td>\n",
       "      <td>668</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181449.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15749177</td>\n",
       "      <td>Okwudiliolisa</td>\n",
       "      <td>627</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49503.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15694510</td>\n",
       "      <td>Hsueh</td>\n",
       "      <td>678</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184866.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15741417</td>\n",
       "      <td>Kao</td>\n",
       "      <td>581</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2</td>\n",
       "      <td>148882.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84560.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15766172</td>\n",
       "      <td>Chiemenam</td>\n",
       "      <td>716</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15068.83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  CustomerId         Surname  CreditScore Geography Gender   Age  Tenure  \\\n",
       "0   0    15674932  Okwudilichukwu          668    France   Male  33.0       3   \n",
       "1   1    15749177   Okwudiliolisa          627    France   Male  33.0       1   \n",
       "2   2    15694510           Hsueh          678    France   Male  40.0      10   \n",
       "3   3    15741417             Kao          581    France   Male  34.0       2   \n",
       "4   4    15766172       Chiemenam          716     Spain   Male  33.0       5   \n",
       "\n",
       "     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "0       0.00              2        1.0             0.0        181449.97   \n",
       "1       0.00              2        1.0             1.0         49503.50   \n",
       "2       0.00              2        1.0             0.0        184866.69   \n",
       "3  148882.54              1        1.0             1.0         84560.88   \n",
       "4       0.00              2        1.0             1.0         15068.83   \n",
       "\n",
       "   Exited  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"train.csv\")\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new columns based on the Gender column\n",
    "dataframe['Is_Male'] = dataframe['Gender'].apply(lambda x: 1 if x == 'Male' else 0)\n",
    "dataframe['Is_Female'] = dataframe['Gender'].apply(lambda x: 1 if x == 'Female' else 0)\n",
    "\n",
    "# Create new columns based on the Geography column\n",
    "dataframe['Is_Germany'] = dataframe['Geography'].apply(lambda x: 1 if x == 'Germany' else 0)\n",
    "dataframe['Is_Spain'] = dataframe['Geography'].apply(lambda x: 1 if x == 'Spain' else 0)\n",
    "dataframe['Is_France'] = dataframe['Geography'].apply(lambda x: 1 if x == 'France' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop non-int columns\n",
    "dataframe.drop(['Geography', 'Gender'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataframe.Exited.values\n",
    "X = dataframe.drop(columns=['id','CustomerId','Surname','Exited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='minority')\n",
    "\n",
    "# fit predictor and target variable\n",
    "x_smote, y_smote = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_smote, y_smote, random_state=42, stratify=y_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a method that creates a new Sequential model with hyperparameter options\n",
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
    "    activation = hp.Choice('activation',['relu','sigmoid'])\n",
    "    \n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "        min_value=1,\n",
    "        max_value=30,\n",
    "        step=5), activation=activation, input_dim=13))\n",
    "\n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 5)):\n",
    "        nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "            min_value=1,\n",
    "            max_value=30,\n",
    "            step=5),\n",
    "            activation=activation))\n",
    "    \n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "    \n",
    "    return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=20,\n",
    "    hyperband_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 56 Complete [00h 01m 49s]\n",
      "val_accuracy: 0.8625051975250244\n",
      "\n",
      "Best val_accuracy So Far: 0.8995803594589233\n",
      "Total elapsed time: 00h 37m 21s\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train_scaled,y_train,epochs=20,validation_data=(X_test_scaled,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Define the deep learning model \n",
    "# nn_model = tf.keras.models.Sequential()\n",
    "# nn_model.add(tf.keras.layers.Dense(units=32, activation=\"relu\", input_dim=13))\n",
    "# nn_model.add(tf.keras.layers.Dense(units=16, activation=\"relu\"))\n",
    "# nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# # Compile the Sequential model together and customise metrics\n",
    "# nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# # Train the model\n",
    "# fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50)\n",
    "\n",
    "# # Evaluate the model using the test data\n",
    "# model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "# print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'first_units': 26, 'num_layers': 4, 'units_0': 26, 'units_1': 21, 'units_2': 21, 'units_3': 11, 'units_4': 11, 'tuner/epochs': 20, 'tuner/initial_epoch': 7, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0018'}\n"
     ]
    }
   ],
   "source": [
    "top_hyper = tuner.get_best_hyperparameters(1)\n",
    "for param in top_hyper:\n",
    "    print(param.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2034/2034 - 1s - loss: 0.2374 - accuracy: 0.8996 - 1s/epoch - 550us/step\n",
      "Loss: 0.2373967319726944, Accuracy: 0.8995803594589233\n"
     ]
    }
   ],
   "source": [
    "top_model = tuner.get_best_models(1)\n",
    "for model in top_model:\n",
    "    model_loss, model_accuracy = model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "    print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6100/6100 [==============================] - 6s 858us/step - loss: 0.2887 - accuracy: 0.8733 - val_loss: 0.2666 - val_accuracy: 0.8843\n",
      "Epoch 2/20\n",
      "6100/6100 [==============================] - 5s 832us/step - loss: 0.2567 - accuracy: 0.8901 - val_loss: 0.2539 - val_accuracy: 0.8912\n",
      "Epoch 3/20\n",
      "6100/6100 [==============================] - 5s 825us/step - loss: 0.2488 - accuracy: 0.8939 - val_loss: 0.2472 - val_accuracy: 0.8943\n",
      "Epoch 4/20\n",
      "6100/6100 [==============================] - 5s 834us/step - loss: 0.2451 - accuracy: 0.8951 - val_loss: 0.2484 - val_accuracy: 0.8945\n",
      "Epoch 5/20\n",
      "6100/6100 [==============================] - 5s 828us/step - loss: 0.2431 - accuracy: 0.8959 - val_loss: 0.2439 - val_accuracy: 0.8959\n",
      "Epoch 6/20\n",
      "6100/6100 [==============================] - 5s 842us/step - loss: 0.2414 - accuracy: 0.8968 - val_loss: 0.2443 - val_accuracy: 0.8957\n",
      "Epoch 7/20\n",
      "6100/6100 [==============================] - 5s 836us/step - loss: 0.2403 - accuracy: 0.8972 - val_loss: 0.2442 - val_accuracy: 0.8959\n",
      "Epoch 8/20\n",
      "6100/6100 [==============================] - 5s 838us/step - loss: 0.2394 - accuracy: 0.8978 - val_loss: 0.2429 - val_accuracy: 0.8956\n",
      "Epoch 9/20\n",
      "6100/6100 [==============================] - 5s 826us/step - loss: 0.2388 - accuracy: 0.8978 - val_loss: 0.2397 - val_accuracy: 0.8983\n",
      "Epoch 10/20\n",
      "6100/6100 [==============================] - 5s 826us/step - loss: 0.2379 - accuracy: 0.8983 - val_loss: 0.2402 - val_accuracy: 0.8970\n",
      "Epoch 11/20\n",
      "6100/6100 [==============================] - 5s 833us/step - loss: 0.2379 - accuracy: 0.8983 - val_loss: 0.2408 - val_accuracy: 0.8981\n",
      "Epoch 12/20\n",
      "6100/6100 [==============================] - 5s 829us/step - loss: 0.2375 - accuracy: 0.8983 - val_loss: 0.2403 - val_accuracy: 0.8978\n",
      "Epoch 13/20\n",
      "6100/6100 [==============================] - 5s 826us/step - loss: 0.2372 - accuracy: 0.8984 - val_loss: 0.2440 - val_accuracy: 0.8953\n",
      "Epoch 14/20\n",
      "6100/6100 [==============================] - 5s 830us/step - loss: 0.2365 - accuracy: 0.8989 - val_loss: 0.2410 - val_accuracy: 0.8974\n",
      "Epoch 15/20\n",
      "6100/6100 [==============================] - 5s 827us/step - loss: 0.2360 - accuracy: 0.8989 - val_loss: 0.2390 - val_accuracy: 0.8984\n",
      "Epoch 16/20\n",
      "6100/6100 [==============================] - 5s 827us/step - loss: 0.2359 - accuracy: 0.8986 - val_loss: 0.2389 - val_accuracy: 0.8978\n",
      "Epoch 17/20\n",
      "6100/6100 [==============================] - 5s 825us/step - loss: 0.2357 - accuracy: 0.8990 - val_loss: 0.2401 - val_accuracy: 0.8977\n",
      "Epoch 18/20\n",
      "6100/6100 [==============================] - 5s 833us/step - loss: 0.2354 - accuracy: 0.8991 - val_loss: 0.2381 - val_accuracy: 0.8984\n",
      "Epoch 19/20\n",
      "6100/6100 [==============================] - 5s 836us/step - loss: 0.2352 - accuracy: 0.8992 - val_loss: 0.2395 - val_accuracy: 0.8983\n",
      "Epoch 20/20\n",
      "6100/6100 [==============================] - 5s 842us/step - loss: 0.2352 - accuracy: 0.8993 - val_loss: 0.2390 - val_accuracy: 0.8979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x25201a327d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top hyperparameters\n",
    "top_hyper = tuner.get_best_hyperparameters(3)\n",
    "\n",
    "# Build and train a model using the top hyperparameters\n",
    "best_model = tuner.hypermodel.build(top_hyper[0])\n",
    "best_model.fit(X_train_scaled, y_train, epochs=20, validation_data=(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5158/5158 [==============================] - 3s 493us/step\n"
     ]
    }
   ],
   "source": [
    "X_scaled = X_scaler.transform(X)\n",
    "\n",
    "predictions = best_model.predict(X_scaled)\n",
    "\n",
    "predicted_labels = (predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_df = pd.DataFrame(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91    130113\n",
      "           1       0.69      0.62      0.65     34921\n",
      "\n",
      "    accuracy                           0.86    165034\n",
      "   macro avg       0.80      0.77      0.78    165034\n",
      "weighted avg       0.86      0.86      0.86    165034\n",
      "\n",
      "\n",
      "Accuracy Score: 0.8606044815007816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_curve, auc\n",
    "\n",
    "conf_matrix = confusion_matrix(y, predicted_labels)\n",
    "\n",
    "class_report = classification_report(y, predicted_labels)\n",
    "\n",
    "accuracy = accuracy_score(y, predicted_labels)\n",
    "\n",
    "# print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nClassification Report:\\n\", class_report)\n",
    "print(\"\\nAccuracy Score:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['smote_nn_model']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "filename = 'smote_nn_model'\n",
    "joblib.dump(best_model, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
